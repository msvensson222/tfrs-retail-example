{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652bea62",
   "metadata": {},
   "source": [
    "# Training TFRS\n",
    "\n",
    " - [ ] Fix the data \n",
    "     - [ ] Get a reasonable amount of data, make sure there is overlap in train/test \n",
    "     - [ ] Set up a flag so we can use all vs. subset of data depending on CPU/GPU\n",
    " - [ ] Set up eval procedure \n",
    "     - [ ] Metrics \n",
    "     - [ ] Coverage/Popularity\n",
    "     - [ ] Qualitative evaluation of predictions \n",
    " - [ ] Baselines\n",
    "     - [ ] Most popular \n",
    "     - [ ] Domain Knowledge \n",
    "     - [ ] kNN\n",
    " - [ ] TFRS\n",
    "     - Simple model \n",
    "     - With Context Features\n",
    "     - Sequential \n",
    "     - Memory Efficient\n",
    " - [ ] Serving \n",
    "     - In memory \n",
    "     - TFS\n",
    " - [ ] E2E with TFX\n",
    " - [ ] Alternatives \n",
    "     - [ ] LightFM, Microsoftrecommenders, Transformer recommends\n",
    " - [ ] Clean Notebook\n",
    "     - [ ] References to Papers / Books\n",
    "     - [ ] Evaluation notes\n",
    "     - [ ] Shortcomings/Future work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c891d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Text\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4d4a7",
   "metadata": {},
   "source": [
    "## **Reading in the Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f81fd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', dtype={'user_no': str, 'item_no': str})\n",
    "test_df = pd.read_csv('test.csv', dtype={'user_no': str, 'item_no': str})\n",
    "\n",
    "# For evaluation\n",
    "item_info_df = pd.read_csv('item_info.csv', dtype={'item_no': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcec8c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TODO:</b> Move all this stuff to EDA notebook so this is a bit more streamlined and we can just \n",
    "read in data that is ready-to-go. \n",
    "    \n",
    "<b>NOTE:</b> Gonna cheat here a bit and make an artificial dataset such that all of the users are repeat\n",
    "    \n",
    "Create **two** versions of the dataset (abbreviated and full) so that we can run on CPU and GPU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33abfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_USERS = 1000\n",
    "\n",
    "overlap_users = set(train_df['user_no']) & set(test_df['user_no'].unique())\n",
    "top_users = train_df[train_df['user_no'].isin(overlap_users)]['user_no'].value_counts()[:NUM_USERS].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3366433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered = train_df.loc[train_df['user_no'].isin(top_users)]\n",
    "test_df_filtered = test_df.loc[test_df['user_no'].isin(top_users)]\n",
    "items = train_df_filtered['item_no'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12c54f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(dict(train_df_filtered))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_df_filtered))\n",
    "\n",
    "items_dataset = tf.data.Dataset.from_tensor_slices(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36196c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'7695529757452122196', shape=(), dtype=string)\n",
      "tf.Tensor(b'1959675403949859161', shape=(), dtype=string)\n",
      "tf.Tensor(b'2588296344401354503', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in items_dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a3ab3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-4011379598502823212'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'7695529757452122196'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'unisex'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'reima'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'trainers'>}\n",
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-4011379598502823212'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'1959675403949859161'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'unisex'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'gola kids'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'trainers'>}\n",
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-4011379598502823212'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'2588296344401354503'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'unisex'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'new balance'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'trainers'>}\n"
     ]
    }
   ],
   "source": [
    "for elem in train_dataset.take(3):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73290630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "9519\n",
      "879\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "unique_users = train_df_filtered['user_no'].unique()\n",
    "unique_items_training = set(train_df_filtered['item_no'])\n",
    "unique_items_test = set(test_df_filtered['item_no'])\n",
    "\n",
    "print(len(unique_users))\n",
    "print(len(unique_items_training))\n",
    "print(len(unique_items_test))\n",
    "print(len(unique_items_test - unique_items_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e4358",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "805b46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "NUM_OOV_INDICES = 1\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_users, \n",
    "      num_oov_indices=NUM_OOV_INDICES),\n",
    "  tf.keras.layers.Embedding(len(unique_users) + NUM_OOV_INDICES, EMBEDDING_DIM)\n",
    "])\n",
    "\n",
    "item_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=items, \n",
    "      num_oov_indices=NUM_OOV_INDICES),\n",
    "  tf.keras.layers.Embedding(len(items) + NUM_OOV_INDICES, EMBEDDING_DIM)\n",
    "])\n",
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=items_dataset.batch(128).map(item_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dbe315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTFRSModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, item_model, task):\n",
    "        super().__init__()\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_no\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_item_embeddings = self.item_model(features[\"item_no\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_item_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1ba2c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>The above is just a convenience!</b> The following class is a simplified version of what\n",
    "is actually going on under-the-hood:\n",
    "\n",
    "```python \n",
    "class NonTFRSModel(tf.keras.Model):\n",
    "    def __init__(self, user_model, item_model, metrics):\n",
    "        \"\"\"\n",
    "        Note that we don't pass in the task! That's because we define \n",
    "        what it is here.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.user_model = user_model \n",
    "        self.item_model = item_model \n",
    "        # When we perform retrieval, the default loss is actually just good \n",
    "        # old CategoricalCrossentropy :) \n",
    "        self._loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.keras.losses.Reduction.SUM\n",
    "        )\n",
    "        self._factorized_metrics = metrics\n",
    "\n",
    "    def calc_loss(self, query_embeddings, candidate_embeddings): \n",
    "        scores = tf.linalg.matmul(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings, \n",
    "            transpose_b=True\n",
    "        )\n",
    "        num_queries, num_candidates = scores.shape\n",
    "        labels = tf.eye(num_queries, num_candidates)\n",
    "        loss = self._loss(y_true=labels, y_pred=scores)\n",
    "        self._factorized_metrics.update_state(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        with tf.GradientTape() as tape: \n",
    "            user_embeddings = self.user_model(features['user_no'])\n",
    "            positive_item_embeddings = self.item_model(features['item_no'])\n",
    "            loss = self.calc_loss(user_embeddings, positive_item_embeddings)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics \n",
    "\n",
    "    def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor: \n",
    "        user_embeddings = self.user_model(features['user_no'])\n",
    "        positive_item_embeddings = self.item_model(features['item_no'])\n",
    "\n",
    "        loss = self.compute_loss(user_embeddings, positive_item_embeddings)        \n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics \n",
    "```\n",
    "\n",
    "We can then instantiate and compile a model like so: \n",
    "\n",
    "```python \n",
    "simple_model = NonTFRSModel(user_model, item_model, metrics)\n",
    "# Need to specify run_eagerly=True because we need the shape of the scores \n",
    "# in the calc_loss function\n",
    "simple_model.compile(optimizer=tf.keras.optimizers.Adam(), run_eagerly=True)\n",
    "```\n",
    "\n",
    "After that we can just train the model the same as below :)\n",
    "\n",
    "</div>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f2f7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTFRSModel(user_model, item_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b7811f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_interactions = train_dataset.map(lambda x: {\n",
    "    'user_no': x['user_no'],\n",
    "    'item_no': x['item_no']\n",
    "})\n",
    "test_dataset_interactions = test_dataset.map(lambda x: {\n",
    "    'user_no': x['user_no'],\n",
    "    'item_no': x['item_no']\n",
    "})\n",
    "\n",
    "cached_train = train_dataset_interactions.shuffle(1_000).batch(1024).cache()\n",
    "cached_test = test_dataset_interactions.batch(512).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f5c6a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 14s 634ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 4.2105e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0013 - factorized_top_k/top_50_categorical_accuracy: 0.0058 - factorized_top_k/top_100_categorical_accuracy: 0.0124 - loss: 6748.2783 - regularization_loss: 0.0000e+00 - total_loss: 6748.2783\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 12s 642ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0118 - factorized_top_k/top_10_categorical_accuracy: 0.0192 - factorized_top_k/top_50_categorical_accuracy: 0.0586 - factorized_top_k/top_100_categorical_accuracy: 0.0912 - loss: 6743.9656 - regularization_loss: 0.0000e+00 - total_loss: 6743.9656\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 17s 883ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0602 - factorized_top_k/top_10_categorical_accuracy: 0.0904 - factorized_top_k/top_50_categorical_accuracy: 0.1961 - factorized_top_k/top_100_categorical_accuracy: 0.2605 - loss: 6739.4066 - regularization_loss: 0.0000e+00 - total_loss: 6739.4066\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 15s 794ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1397 - factorized_top_k/top_10_categorical_accuracy: 0.1994 - factorized_top_k/top_50_categorical_accuracy: 0.3690 - factorized_top_k/top_100_categorical_accuracy: 0.4554 - loss: 6733.3974 - regularization_loss: 0.0000e+00 - total_loss: 6733.3974\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 20s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.2091 - factorized_top_k/top_10_categorical_accuracy: 0.3062 - factorized_top_k/top_50_categorical_accuracy: 0.5239 - factorized_top_k/top_100_categorical_accuracy: 0.6129 - loss: 6725.1691 - regularization_loss: 0.0000e+00 - total_loss: 6725.1691\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 13s 700ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.2518 - factorized_top_k/top_10_categorical_accuracy: 0.3898 - factorized_top_k/top_50_categorical_accuracy: 0.6440 - factorized_top_k/top_100_categorical_accuracy: 0.7235 - loss: 6714.0667 - regularization_loss: 0.0000e+00 - total_loss: 6714.0667\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 18s 991ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.2762 - factorized_top_k/top_10_categorical_accuracy: 0.4481 - factorized_top_k/top_50_categorical_accuracy: 0.7212 - factorized_top_k/top_100_categorical_accuracy: 0.7874 - loss: 6699.5379 - regularization_loss: 0.0000e+00 - total_loss: 6699.5379\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 15s 753ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.2916 - factorized_top_k/top_10_categorical_accuracy: 0.4872 - factorized_top_k/top_50_categorical_accuracy: 0.7691 - factorized_top_k/top_100_categorical_accuracy: 0.8224 - loss: 6681.1391 - regularization_loss: 0.0000e+00 - total_loss: 6681.1391\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 13s 706ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.3005 - factorized_top_k/top_10_categorical_accuracy: 0.5117 - factorized_top_k/top_50_categorical_accuracy: 0.7952 - factorized_top_k/top_100_categorical_accuracy: 0.8449 - loss: 6658.5386 - regularization_loss: 0.0000e+00 - total_loss: 6658.5386\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 13s 709ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.3063 - factorized_top_k/top_10_categorical_accuracy: 0.5306 - factorized_top_k/top_50_categorical_accuracy: 0.8103 - factorized_top_k/top_100_categorical_accuracy: 0.8588 - loss: 6631.5068 - regularization_loss: 0.0000e+00 - total_loss: 6631.5068\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4dbd5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e8f176c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 438ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0130 - factorized_top_k/top_5_categorical_accuracy: 0.0500 - factorized_top_k/top_10_categorical_accuracy: 0.0820 - factorized_top_k/top_50_categorical_accuracy: 0.1170 - factorized_top_k/top_100_categorical_accuracy: 0.1270 - loss: 3069.4933 - regularization_loss: 0.0000e+00 - total_loss: 3069.4933\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b235b",
   "metadata": {},
   "source": [
    "## Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bfea60c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x14991ad10>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends items out of the entire items dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((items_dataset.batch(100), items_dataset.batch(100).map(model.item_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e8b1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_no</th>\n",
       "      <th>item_no</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377129</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-7865088438347131541</td>\n",
       "      <td>girls</td>\n",
       "      <td>wheat</td>\n",
       "      <td>bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377130</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-4157873162967126783</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>headwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377131</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-2142740165482218263</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>headwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377132</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>3748431471949385807</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>swimwear and coverups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377133</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-2860174162663871712</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>headwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377134</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-2195934864809708124</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377135</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>1513658394069720986</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377136</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-6850173515075499791</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>clothing sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377137</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-2195934864809708124</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377138</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>1513658394069720986</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377139</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>9133549819232803355</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377140</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>450149709663166789</td>\n",
       "      <td>boys</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377141</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-5676845913022198698</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377142</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-3187741677834538213</td>\n",
       "      <td>unisex</td>\n",
       "      <td>wheat</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377143</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>5745513694012740270</td>\n",
       "      <td>unisex</td>\n",
       "      <td>mini a ture</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377144</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>619366256844196923</td>\n",
       "      <td>girls</td>\n",
       "      <td>wheat</td>\n",
       "      <td>bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377145</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-7865088438347131541</td>\n",
       "      <td>girls</td>\n",
       "      <td>wheat</td>\n",
       "      <td>bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377146</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>-2860174162663871712</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>headwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377147</th>\n",
       "      <td>1145355627971110554</td>\n",
       "      <td>1515992951769899823</td>\n",
       "      <td>girls</td>\n",
       "      <td>carrément beau</td>\n",
       "      <td>jumpers and knitwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_no               item_no gender_description  \\\n",
       "377129  1145355627971110554  -7865088438347131541              girls   \n",
       "377130  1145355627971110554  -4157873162967126783             unisex   \n",
       "377131  1145355627971110554  -2142740165482218263             unisex   \n",
       "377132  1145355627971110554   3748431471949385807             unisex   \n",
       "377133  1145355627971110554  -2860174162663871712             unisex   \n",
       "377134  1145355627971110554  -2195934864809708124             unisex   \n",
       "377135  1145355627971110554   1513658394069720986             unisex   \n",
       "377136  1145355627971110554  -6850173515075499791             unisex   \n",
       "377137  1145355627971110554  -2195934864809708124             unisex   \n",
       "377138  1145355627971110554   1513658394069720986             unisex   \n",
       "377139  1145355627971110554   9133549819232803355             unisex   \n",
       "377140  1145355627971110554    450149709663166789               boys   \n",
       "377141  1145355627971110554  -5676845913022198698             unisex   \n",
       "377142  1145355627971110554  -3187741677834538213             unisex   \n",
       "377143  1145355627971110554   5745513694012740270             unisex   \n",
       "377144  1145355627971110554    619366256844196923              girls   \n",
       "377145  1145355627971110554  -7865088438347131541              girls   \n",
       "377146  1145355627971110554  -2860174162663871712             unisex   \n",
       "377147  1145355627971110554   1515992951769899823              girls   \n",
       "\n",
       "                 brand          product_group  \n",
       "377129           wheat                bottoms  \n",
       "377130          kuling               headwear  \n",
       "377131          kuling               headwear  \n",
       "377132          kuling  swimwear and coverups  \n",
       "377133          kuling               headwear  \n",
       "377134           wheat  fleeces and midlayers  \n",
       "377135           wheat  fleeces and midlayers  \n",
       "377136           wheat          clothing sets  \n",
       "377137           wheat  fleeces and midlayers  \n",
       "377138           wheat  fleeces and midlayers  \n",
       "377139           wheat  fleeces and midlayers  \n",
       "377140           wheat  fleeces and midlayers  \n",
       "377141           wheat  fleeces and midlayers  \n",
       "377142           wheat  fleeces and midlayers  \n",
       "377143     mini a ture  fleeces and midlayers  \n",
       "377144           wheat                bottoms  \n",
       "377145           wheat                bottoms  \n",
       "377146          kuling               headwear  \n",
       "377147  carrément beau   jumpers and knitwear  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user = np.random.choice(train_df_filtered['user_no'].unique())\n",
    "train_df_filtered.loc[train_df_filtered['user_no'] == random_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a0938ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 ms, sys: 6.71 ms, total: 11.3 ms\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([random_user]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "745bfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 ms, sys: 704 µs, total: 4.79 ms\n",
      "Wall time: 3.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "items_to_exclude = train_df_filtered.loc[train_df_filtered['user_no'] == random_user]['item_no'].unique()\n",
    "_, titles = index.query_with_exclusions(tf.constant([random_user]), \n",
    "                                       tf.constant([items_to_exclude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ee4f6e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_no</th>\n",
       "      <th>colour</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_group</th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>-6452537443298138438</td>\n",
       "      <td>cream</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bobo choses</td>\n",
       "      <td>all in ones</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16614</th>\n",
       "      <td>-5461181132081057096</td>\n",
       "      <td>blue</td>\n",
       "      <td>girls</td>\n",
       "      <td>burberry</td>\n",
       "      <td>dresses</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21874</th>\n",
       "      <td>-873465860918484678</td>\n",
       "      <td>navy</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>sandals</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39166</th>\n",
       "      <td>-8429863690086218988</td>\n",
       "      <td>pink</td>\n",
       "      <td>girls</td>\n",
       "      <td>adidas</td>\n",
       "      <td>trainers</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41496</th>\n",
       "      <td>8659013735764980519</td>\n",
       "      <td>grey</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bugaboo</td>\n",
       "      <td>stroller parts and customisati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42154</th>\n",
       "      <td>7480282260445719099</td>\n",
       "      <td>black</td>\n",
       "      <td>boys</td>\n",
       "      <td>nike</td>\n",
       "      <td>trainers</td>\n",
       "      <td>0.375</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52105</th>\n",
       "      <td>1493209376961654965</td>\n",
       "      <td>navy</td>\n",
       "      <td>boys</td>\n",
       "      <td>didriksons</td>\n",
       "      <td>coats and jackets</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54505</th>\n",
       "      <td>-6447463798668859639</td>\n",
       "      <td>purple</td>\n",
       "      <td>unisex</td>\n",
       "      <td>buddy &amp; hope</td>\n",
       "      <td>stroller accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>-7634805924562764179</td>\n",
       "      <td>black</td>\n",
       "      <td>unisex</td>\n",
       "      <td>reima</td>\n",
       "      <td>trainers</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58036</th>\n",
       "      <td>-5678741866268285557</td>\n",
       "      <td>blue</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bobo choses</td>\n",
       "      <td>swimwear and coverups</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_no  colour gender_description         brand  \\\n",
       "8723   -6452537443298138438   cream             unisex   bobo choses   \n",
       "16614  -5461181132081057096    blue              girls      burberry   \n",
       "21874   -873465860918484678    navy             unisex        kuling   \n",
       "39166  -8429863690086218988    pink              girls        adidas   \n",
       "41496   8659013735764980519    grey             unisex       bugaboo   \n",
       "42154   7480282260445719099   black               boys          nike   \n",
       "52105   1493209376961654965    navy               boys    didriksons   \n",
       "54505  -6447463798668859639  purple             unisex  buddy & hope   \n",
       "56913  -7634805924562764179   black             unisex         reima   \n",
       "58036  -5678741866268285557    blue             unisex   bobo choses   \n",
       "\n",
       "                        product_group  min_age  max_age  \n",
       "8723                      all in ones    1.000     11.0  \n",
       "16614                         dresses    2.000     14.0  \n",
       "21874                         sandals    0.875      6.0  \n",
       "39166                        trainers    4.000     10.0  \n",
       "41496  stroller parts and customisati      NaN      NaN  \n",
       "42154                        trainers    0.375      5.0  \n",
       "52105               coats and jackets    1.000      9.0  \n",
       "54505            stroller accessories      NaN      NaN  \n",
       "56913                        trainers    0.875      5.0  \n",
       "58036           swimwear and coverups    1.000     11.0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = [item.numpy().decode() for item in titles[0]]\n",
    "item_info_df.loc[item_info_df['item_no'].isin(recommendations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0766e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2fb2f8",
   "metadata": {},
   "source": [
    "## **Baselines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236cd02",
   "metadata": {},
   "source": [
    "### **Top Items**\n",
    "\n",
    "**Let's find the top 100 items in the training dataset and always predict during the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "48243643",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOP_ITEMS = 100\n",
    "top_items = train_df_filtered['item_no'].value_counts()[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "710870d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "top_items_in_test_dataset = test_df_filtered.loc[test_df_filtered['item_no'].isin(top_items)]\n",
    "\n",
    "print(len(top_items_in_test_dataset))\n",
    "print(len(test_df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a15534b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (1, 5, 10, 50, 100)\n",
    "metrics = [tf.keras.metrics.Mean() for k in ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4bae23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_candidates = tf.expand_dims(tf.constant(test_df_filtered['item_no'].values), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3644c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_candidates = tf.expand_dims(top_items, 1)\n",
    "retrieved_candidates = tf.transpose(tf.repeat(retrieved_candidates, tf.constant(true_candidates.shape[0]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d76af61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match = tf.cast(tf.math.equal(true_candidates, retrieved_candidates), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "05af47ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cb5bd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, metric in zip(ks, metrics):\n",
    "    # By slicing until :k we assume scores are sorted.\n",
    "    # Clip to only count multiple matches once.\n",
    "    match_found = tf.clip_by_value(\n",
    "        tf.reduce_sum(ids_match[:, :k], axis=1, keepdims=True),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "    metric.update_state(match_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c8e0f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003, shape=(), dtype=float32)\n",
      "tf.Tensor(0.007, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027, shape=(), dtype=float32)\n",
      "tf.Tensor(0.051, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(metric.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20487cf0",
   "metadata": {},
   "source": [
    "### **Top Items Domain Knowledge**\n",
    "\n",
    "Since the test data is in November let's exclude certain product groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3bf3bb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jumpers and knitwear', 'coveralls', 'boots', 'trainers',\n",
       "       'dresses', 'tops', 'clothing sets', 'coats and jackets',\n",
       "       'stroller accessories', 'fleeces and midlayers', 'winter sets',\n",
       "       'sandals', 'bottoms', 'gloves and mittens', 'role play',\n",
       "       'stationary', 'headwear'], dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_info_df.loc[item_info_df['item_no'].isin(top_items)]['product_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "be7b5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS_TO_INCLUDE = ['jumpers and knitwear', 'coveralls', 'boots', 'coats and jackets', 'stroller accessories', \n",
    "                      'fleeces and midlayers', 'winter sets', 'gloves and mittens', 'headwear']\n",
    "\n",
    "items_to_consider = item_info_df.loc[item_info_df['product_group'].isin(GROUPS_TO_INCLUDE)]['item_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c5278f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items_filtered = train_df_filtered[\n",
    "    train_df_filtered['item_no'].isin(items_to_consider)]['item_no'].value_counts()[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ae2da02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(top_items_filtered) - set(top_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c0ffdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_candidates = tf.expand_dims(top_items_filtered, 1)\n",
    "retrieved_candidates = tf.transpose(tf.repeat(retrieved_candidates, tf.constant(true_candidates.shape[0]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6a0a3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match = tf.cast(tf.math.equal(true_candidates, retrieved_candidates), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "71cd7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.Mean() for k in ks]\n",
    "for k, metric in zip(ks, metrics):\n",
    "    # By slicing until :k we assume scores are sorted.\n",
    "    # Clip to only count multiple matches once.\n",
    "    match_found = tf.clip_by_value(\n",
    "        tf.reduce_sum(ids_match[:, :k], axis=1, keepdims=True),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "    metric.update_state(match_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "afbfb9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011, shape=(), dtype=float32)\n",
      "tf.Tensor(0.031, shape=(), dtype=float32)\n",
      "tf.Tensor(0.061, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92065469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfrs-retail-example",
   "language": "python",
   "name": "tfrs-retail-example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
