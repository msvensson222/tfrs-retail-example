{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652bea62",
   "metadata": {},
   "source": [
    "# Training TFRS\n",
    "\n",
    " - [ ] Fix the data \n",
    "     - [x] Get a reasonable amount of data, make sure there is overlap in train/test \n",
    "     - [ ] Set up a flag so we can use all vs. subset of data depending on CPU/GPU\n",
    " - [ ] Set up eval procedure - **Clean this up a bit more**\n",
    "     - [x] Metrics \n",
    "     - [ ] Coverage/Popularity\n",
    "     - [x] Qualitative evaluation of predictions \n",
    " - [x] Baselines - **Done, just need to clean**\n",
    "     - [x] Most popular \n",
    "     - [x] Domain Knowledge \n",
    "     - [x] kNN\n",
    " - [ ] TFRS\n",
    "     - [x] Simple model \n",
    "     - [ ] With Context Features\n",
    "     - [ ] Sequential \n",
    "     - [ ] Memory Efficient\n",
    " - [ ] Serving \n",
    "     - [x] In memory \n",
    "     - [ ] TFS\n",
    " - [ ] E2E with TFX\n",
    " - [ ] Alternatives \n",
    "     - [ ] LightFM, Microsoftrecommenders, Transformer recommends\n",
    " - [ ] Clean Notebook\n",
    "     - [ ] References to Papers / Books\n",
    "     - [ ] Evaluation notes\n",
    "     - [ ] Shortcomings/Future work \n",
    "    \n",
    "After doing with context features, do a more advanced on GPU, and then do E2E with TFX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c891d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Text\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4d4a7",
   "metadata": {},
   "source": [
    "# **Reading in the Data** \n",
    "\n",
    "First we will read in the training and test data. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> See <code>EDA.ipynb</code> for analysis on the data and details on how the train and test sets were created. \n",
    "</div>\n",
    "\n",
    "In the following cells we will cheat a bit and create an even smaller version of the dataset so that we can train on a reasonable amount of time on a CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81fd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', dtype={'user_no': str, 'item_no': str})\n",
    "test_df = pd.read_csv('test.csv', dtype={'user_no': str, 'item_no': str})\n",
    "\n",
    "# For evaluation\n",
    "item_info_df = pd.read_csv('item_info.csv', dtype={'item_no': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6468315",
   "metadata": {},
   "source": [
    "In order to create the smaller version of the dataset so that we can train quickly, we will just take the top few thousand users. Note that this will signficantly change the distribution of the features in the dataset and that we will not be able to accurately assess how well any trained models can deal with the user cold-start problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f530f60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36909\n",
      "2273\n"
     ]
    }
   ],
   "source": [
    "NUM_USERS = 2000\n",
    "\n",
    "top_users = train_df['user_no'].value_counts()[:NUM_USERS].index\n",
    "\n",
    "# Create smaller versions of the dataset\n",
    "train_df_filtered = train_df.loc[train_df['user_no'].isin(top_users)]\n",
    "test_df_filtered = test_df.loc[test_df['user_no'].isin(top_users)]\n",
    "# Separately store the 'catalogue' of items so we can use them as our candidates\n",
    "items = train_df_filtered['item_no'].unique()\n",
    "\n",
    "print(len(train_df_filtered))\n",
    "print(len(test_df_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260ea11",
   "metadata": {},
   "source": [
    "In the following cell we create TensorFlow datasets out of the Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c54f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 15:08:35.681987: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(dict(train_df_filtered))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_df_filtered))\n",
    "\n",
    "items_dataset = tf.data.Dataset.from_tensor_slices(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c9ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'-1119687312509640915', shape=(), dtype=string)\n",
      "tf.Tensor(b'-3219910350938683317', shape=(), dtype=string)\n",
      "tf.Tensor(b'1179978263120783371', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in items_dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3ab3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-2683506524939646253'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-1119687312509640915'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'unisex'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'reima'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'boots'>, 'first_interaction_month': <tf.Tensor: shape=(), dtype=int64, numpy=11>}\n",
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-8270295623916047084'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-3219910350938683317'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'boys'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'moschino kid-teen'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'tops'>, 'first_interaction_month': <tf.Tensor: shape=(), dtype=int64, numpy=11>}\n",
      "{'user_no': <tf.Tensor: shape=(), dtype=string, numpy=b'-1493854771764820101'>, 'item_no': <tf.Tensor: shape=(), dtype=string, numpy=b'1179978263120783371'>, 'gender_description': <tf.Tensor: shape=(), dtype=string, numpy=b'girls'>, 'brand': <tf.Tensor: shape=(), dtype=string, numpy=b'molo'>, 'product_group': <tf.Tensor: shape=(), dtype=string, numpy=b'tops'>, 'first_interaction_month': <tf.Tensor: shape=(), dtype=int64, numpy=9>}\n"
     ]
    }
   ],
   "source": [
    "for elem in train_dataset.take(3):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73290630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 unique users in the training dataset\n",
      "There are 1568 unique users in the test dataset\n",
      "There are 20177 unique items in the training dataset\n",
      "There are 2111 unique items in the test dataset\n",
      "There are 786 'unseen' items in the test dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {train_df_filtered['user_no'].nunique()} unique users in the training dataset\")\n",
    "print(f\"There are {test_df_filtered['user_no'].nunique()} unique users in the test dataset\")\n",
    "print(f\"There are {train_df_filtered['item_no'].nunique()} unique items in the training dataset\")\n",
    "print(f\"There are {test_df_filtered['item_no'].nunique()} unique items in the test dataset\")\n",
    "\n",
    "num_new_items_in_test = len(set(test_df_filtered['item_no']) - set(train_df_filtered['item_no']))\n",
    "print(f\"There are {num_new_items_in_test} 'unseen' items in the test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65826210",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "\n",
    "We will start by creating a very simple model similar to the one created in [the TFRS basic retrieval tutorial](https://www.tensorflow.org/recommenders/examples/basic_retrieval). Quoting from the tutorial, the model will be created by two-submodels: \n",
    "\n",
    "> 1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features\n",
    "> 2. A candidate model computing the candidate representation (an equally-sized vector using the candidate features\n",
    "> \n",
    "> The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\n",
    "\n",
    "For our use case, we will pretend that we want to recommend items to users. As such, our **query** model will produce representations of the **users** (and potentially additional **context**, such as time, device, etc.) and our **candidate** model will produce representations of the **items**. \n",
    "\n",
    "For the rest of the notebook we will refer to the \"query\" model as a `user_model` and the \"candidate\" model as a `item_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a734989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df, feature, top_n=None):\n",
    "    return df[feature].value_counts()[:top_n].index\n",
    "\n",
    "def create_embedding_model(feature, num_oov_indices=1, embedding_dim=32):\n",
    "    feature_vocab = get_vocab(train_df_filtered, feature)\n",
    "    feature_input = tf.keras.Input(shape=(), dtype=\"string\", name=feature)\n",
    "    feature_lookup = tf.keras.layers.StringLookup(\n",
    "        vocabulary=feature_vocab,\n",
    "        mask_token=None,\n",
    "        num_oov_indices=num_oov_indices,\n",
    "        name=f\"{feature}_lookup\"\n",
    "    )(feature_input)\n",
    "    feature_embedding = tf.keras.layers.Embedding(len(feature_vocab) + num_oov_indices, \n",
    "                                                  embedding_dim)(feature_lookup)\n",
    "    return tf.keras.models.Model(feature_input, feature_embedding)\n",
    "\n",
    "class SimpleTFRSModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, item_model, task):\n",
    "        super().__init__()\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "            \n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model\n",
    "        # and item features to pass to the item model. Use the returned embeddings \n",
    "        # to calculate the loss\n",
    "        user_embeddings = self.user_model(features['user_no'])\n",
    "        positive_item_embeddings = self.item_model(features['item_no'])\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_item_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a70e26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = create_embedding_model(\"user_no\")\n",
    "item_model = create_embedding_model(\"item_no\")\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=items_dataset.batch(128).map(item_model)\n",
    ")\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")\n",
    "\n",
    "simple_tfrs_model = SimpleTFRSModel(user_model, item_model, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7778cb09",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>The above is just a convenience!</b> The following class is a simplified version of what\n",
    "is actually going on under-the-hood:\n",
    "\n",
    "```python \n",
    "class NonTFRSModel(tf.keras.Model):\n",
    "    def __init__(self, user_model, item_model, metrics):\n",
    "        \"\"\"\n",
    "        Note that we don't pass in the task! That's because we define \n",
    "        what the task is here.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.user_model = user_model \n",
    "        self.item_model = item_model \n",
    "        # When we perform retrieval, the default loss is actually just good \n",
    "        # old CategoricalCrossentropy :) \n",
    "        self._loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.keras.losses.Reduction.SUM\n",
    "        )\n",
    "        self._factorized_metrics = metrics\n",
    "\n",
    "    def calc_loss(self, query_embeddings, candidate_embeddings): \n",
    "        scores = tf.linalg.matmul(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings, \n",
    "            transpose_b=True\n",
    "        )\n",
    "        num_queries, num_candidates = scores.shape\n",
    "        labels = tf.eye(num_queries, num_candidates)\n",
    "        loss = self._loss(y_true=labels, y_pred=scores)\n",
    "        self._factorized_metrics.update_state(\n",
    "            query_embeddings, \n",
    "            candidate_embeddings\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        with tf.GradientTape() as tape: \n",
    "            user_embeddings = self.user_model(features['user_no'])\n",
    "            positive_item_embeddings = self.item_model(features['item_no'])\n",
    "            loss = self.calc_loss(user_embeddings, positive_item_embeddings)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics \n",
    "\n",
    "    def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor: \n",
    "        user_embeddings = self.user_model(features['user_no'])\n",
    "        positive_item_embeddings = self.item_model(features['item_no'])\n",
    "\n",
    "        loss = self.compute_loss(user_embeddings, positive_item_embeddings)        \n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        return metrics \n",
    "```\n",
    "\n",
    "We can then instantiate and compile a model like so: \n",
    "\n",
    "```python \n",
    "simple_model = NonTFRSModel(user_model, item_model, metrics)\n",
    "# Need to specify run_eagerly=True because we need the shape of the scores \n",
    "# in the calc_loss function\n",
    "simple_model.compile(optimizer=tf.keras.optimizers.Adam(), run_eagerly=True)\n",
    "```\n",
    "\n",
    "After that we can just train the model the same as below :)\n",
    "\n",
    "</div>\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7811f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_interactions = train_dataset.map(lambda x: {\n",
    "    'user_no': x['user_no'],\n",
    "    'item_no': x['item_no']\n",
    "})\n",
    "test_dataset_interactions = test_dataset.map(lambda x: {\n",
    "    'user_no': x['user_no'],\n",
    "    'item_no': x['item_no']\n",
    "})\n",
    "\n",
    "cached_train = train_dataset_interactions.shuffle(1_000).batch(4096).cache()\n",
    "cached_test = test_dataset_interactions.batch(512).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "507cdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_factorized_top_k/top_100_categorical_accuracy', patience=3, restore_best_weights=True, mode=\"max\")\n",
    "\n",
    "simple_tfrs_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5c6a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 8s 715ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 27905.7739 - regularization_loss: 0.0000e+00 - total_loss: 27905.7739 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 4.3995e-04 - val_factorized_top_k/top_10_categorical_accuracy: 0.0013 - val_factorized_top_k/top_50_categorical_accuracy: 0.0062 - val_factorized_top_k/top_100_categorical_accuracy: 0.0110 - val_loss: 1218.6392 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1218.6392\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 6s 678ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 27761.1745 - regularization_loss: 0.0000e+00 - total_loss: 27761.1745 - val_factorized_top_k/top_1_categorical_accuracy: 4.3995e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0013 - val_factorized_top_k/top_10_categorical_accuracy: 0.0044 - val_factorized_top_k/top_50_categorical_accuracy: 0.0251 - val_factorized_top_k/top_100_categorical_accuracy: 0.0378 - val_loss: 1217.3500 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1217.3500\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 6s 635ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 26936.7641 - regularization_loss: 0.0000e+00 - total_loss: 26936.7641 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0022 - val_factorized_top_k/top_10_categorical_accuracy: 0.0079 - val_factorized_top_k/top_50_categorical_accuracy: 0.0273 - val_factorized_top_k/top_100_categorical_accuracy: 0.0466 - val_loss: 1211.2417 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1211.2417\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 7s 700ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 24546.2916 - regularization_loss: 0.0000e+00 - total_loss: 24546.2916 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0013 - val_factorized_top_k/top_10_categorical_accuracy: 0.0070 - val_factorized_top_k/top_50_categorical_accuracy: 0.0286 - val_factorized_top_k/top_100_categorical_accuracy: 0.0480 - val_loss: 1212.9525 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1212.9525\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 6s 674ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 20859.5394 - regularization_loss: 0.0000e+00 - total_loss: 20859.5394 - val_factorized_top_k/top_1_categorical_accuracy: 4.3995e-04 - val_factorized_top_k/top_5_categorical_accuracy: 4.3995e-04 - val_factorized_top_k/top_10_categorical_accuracy: 0.0022 - val_factorized_top_k/top_50_categorical_accuracy: 0.0295 - val_factorized_top_k/top_100_categorical_accuracy: 0.0440 - val_loss: 1242.3590 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1242.3590\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 6s 598ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 16880.8695 - regularization_loss: 0.0000e+00 - total_loss: 16880.8695 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 4.3995e-04 - val_factorized_top_k/top_10_categorical_accuracy: 8.7989e-04 - val_factorized_top_k/top_50_categorical_accuracy: 0.0216 - val_factorized_top_k/top_100_categorical_accuracy: 0.0343 - val_loss: 1299.8914 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1299.8914\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 6s 615ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13362.8489 - regularization_loss: 0.0000e+00 - total_loss: 13362.8489 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0167 - val_factorized_top_k/top_100_categorical_accuracy: 0.0295 - val_loss: 1375.7743 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1375.7743\n"
     ]
    }
   ],
   "source": [
    "history = simple_tfrs_model.fit(cached_train, epochs=10, validation_data=cached_test,\n",
    "                  callbacks=[callback_early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3d1ff",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c20ad450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 48s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0309 - factorized_top_k/top_5_categorical_accuracy: 0.1822 - factorized_top_k/top_10_categorical_accuracy: 0.3318 - factorized_top_k/top_50_categorical_accuracy: 0.8337 - factorized_top_k/top_100_categorical_accuracy: 0.9410 - loss: 21597.6590 - regularization_loss: 0.0000e+00 - total_loss: 21597.6590\n",
      "5/5 [==============================] - 3s 669ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0070 - factorized_top_k/top_50_categorical_accuracy: 0.0286 - factorized_top_k/top_100_categorical_accuracy: 0.0480 - loss: 2510.2016 - regularization_loss: 0.0000e+00 - total_loss: 2510.2016\n"
     ]
    }
   ],
   "source": [
    "train_results = simple_tfrs_model.evaluate(cached_train, return_dict=True)\n",
    "test_results = simple_tfrs_model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a671427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train top-100 accuracy:  0.9409900307655334\n",
      "Test top-100 accuracy:  0.047954246401786804\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train top-100 accuracy:  {train_results['factorized_top_k/top_100_categorical_accuracy']}\")\n",
    "print(f\"Test top-100 accuracy:  {test_results['factorized_top_k/top_100_categorical_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a3137",
   "metadata": {},
   "source": [
    "Severe overfitting! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128f4db",
   "metadata": {},
   "source": [
    "## Serving and Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfea60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(simple_tfrs_model.user_model)\n",
    "# recommends items out of the entire items dataset.\n",
    "_ = index.index_from_dataset(\n",
    "        tf.data.Dataset.zip((items_dataset.batch(100), \n",
    "                             items_dataset.batch(100).map(simple_tfrs_model.item_model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6960f930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_no</th>\n",
       "      <th>item_no</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_group</th>\n",
       "      <th>first_interaction_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-904384509832430199</td>\n",
       "      <td>unisex</td>\n",
       "      <td>reima</td>\n",
       "      <td>boots</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>8252940203222144649</td>\n",
       "      <td>unisex</td>\n",
       "      <td>stoy</td>\n",
       "      <td>first toys and baby toys</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95437</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-4483740504516161354</td>\n",
       "      <td>unisex</td>\n",
       "      <td>najell</td>\n",
       "      <td>carriers and slings</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131933</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>582854757623314903</td>\n",
       "      <td>girls</td>\n",
       "      <td>jacadi</td>\n",
       "      <td>all in ones</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144638</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>3470588284991950186</td>\n",
       "      <td>girls</td>\n",
       "      <td>bonpoint</td>\n",
       "      <td>eyewear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186084</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-7704887968268080568</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192091</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>6858248263439961548</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bbhugme</td>\n",
       "      <td>breast feeding</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193257</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-2927729873393290990</td>\n",
       "      <td>unisex</td>\n",
       "      <td>reima</td>\n",
       "      <td>gloves and mittens</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204802</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>8818496003429638190</td>\n",
       "      <td>unisex</td>\n",
       "      <td>stoy</td>\n",
       "      <td>first toys and baby toys</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257828</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>7345485044526784625</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>baselayers</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324028</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>5747651500047780376</td>\n",
       "      <td>unisex</td>\n",
       "      <td>najell</td>\n",
       "      <td>carriers and slings</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329815</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-1478446127992222424</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>scarves</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349753</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-5181384967627450769</td>\n",
       "      <td>unisex</td>\n",
       "      <td>ergobaby</td>\n",
       "      <td>carriers and slings</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429168</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>-4992667810789893646</td>\n",
       "      <td>unisex</td>\n",
       "      <td>najell</td>\n",
       "      <td>carriers and slings</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472694</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>8187045854495320925</td>\n",
       "      <td>girls</td>\n",
       "      <td>jacadi</td>\n",
       "      <td>clothing sets</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549320</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>2207239921565592192</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>clothing sets</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573286</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>2484459689621418582</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647356</th>\n",
       "      <td>-2397642298805843183</td>\n",
       "      <td>2431937393221782146</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>all in ones</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_no               item_no gender_description  \\\n",
       "8923    -2397642298805843183   -904384509832430199             unisex   \n",
       "30226   -2397642298805843183   8252940203222144649             unisex   \n",
       "95437   -2397642298805843183  -4483740504516161354             unisex   \n",
       "131933  -2397642298805843183    582854757623314903              girls   \n",
       "144638  -2397642298805843183   3470588284991950186              girls   \n",
       "186084  -2397642298805843183  -7704887968268080568             unisex   \n",
       "192091  -2397642298805843183   6858248263439961548             unisex   \n",
       "193257  -2397642298805843183  -2927729873393290990             unisex   \n",
       "204802  -2397642298805843183   8818496003429638190             unisex   \n",
       "257828  -2397642298805843183   7345485044526784625             unisex   \n",
       "324028  -2397642298805843183   5747651500047780376             unisex   \n",
       "329815  -2397642298805843183  -1478446127992222424             unisex   \n",
       "349753  -2397642298805843183  -5181384967627450769             unisex   \n",
       "429168  -2397642298805843183  -4992667810789893646             unisex   \n",
       "472694  -2397642298805843183   8187045854495320925              girls   \n",
       "549320  -2397642298805843183   2207239921565592192             unisex   \n",
       "573286  -2397642298805843183   2484459689621418582             unisex   \n",
       "647356  -2397642298805843183   2431937393221782146             unisex   \n",
       "\n",
       "           brand             product_group  first_interaction_month  \n",
       "8923       reima                     boots                       10  \n",
       "30226       stoy  first toys and baby toys                       11  \n",
       "95437     najell       carriers and slings                       11  \n",
       "131933    jacadi               all in ones                       10  \n",
       "144638  bonpoint                   eyewear                        3  \n",
       "186084    kuling     fleeces and midlayers                       10  \n",
       "192091   bbhugme            breast feeding                        2  \n",
       "193257     reima        gloves and mittens                       10  \n",
       "204802      stoy  first toys and baby toys                       11  \n",
       "257828    kuling                baselayers                       11  \n",
       "324028    najell       carriers and slings                        3  \n",
       "329815    kuling                   scarves                       10  \n",
       "349753  ergobaby       carriers and slings                       11  \n",
       "429168    najell       carriers and slings                        3  \n",
       "472694    jacadi             clothing sets                       10  \n",
       "549320    kuling             clothing sets                       10  \n",
       "573286    kuling     fleeces and midlayers                       10  \n",
       "647356    kuling               all in ones                       10  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user = np.random.choice(train_df_filtered['user_no'].unique())\n",
    "train_df_filtered.loc[train_df_filtered['user_no'] == random_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0938ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 ms, sys: 3.33 ms, total: 8.28 ms\n",
      "Wall time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([random_user]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "745bfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 557 ms, sys: 77 ms, total: 634 ms\n",
      "Wall time: 817 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "items_to_exclude = train_df_filtered.loc[train_df_filtered['user_no'] == random_user]['item_no'].unique()\n",
    "_, titles = index.query_with_exclusions(tf.constant([random_user]), \n",
    "                                       tf.constant([items_to_exclude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2397d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_no</th>\n",
       "      <th>colour</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_group</th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>-1690395835756691110</td>\n",
       "      <td>purple</td>\n",
       "      <td>girls</td>\n",
       "      <td>mini rodini</td>\n",
       "      <td>dresses</td>\n",
       "      <td>0.875</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>4011112455912821856</td>\n",
       "      <td>beige</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>coveralls</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9659</th>\n",
       "      <td>-92825680858531790</td>\n",
       "      <td>beige</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>fleeces and midlayers</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12558</th>\n",
       "      <td>6592676930236846124</td>\n",
       "      <td>grey</td>\n",
       "      <td>unisex</td>\n",
       "      <td>buddy &amp; hope</td>\n",
       "      <td>baby changing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>6032649609097040334</td>\n",
       "      <td>blue</td>\n",
       "      <td>unisex</td>\n",
       "      <td>stoy</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>6.000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30965</th>\n",
       "      <td>-7258898587632840201</td>\n",
       "      <td>blue</td>\n",
       "      <td>boys</td>\n",
       "      <td>jacadi</td>\n",
       "      <td>coveralls</td>\n",
       "      <td>0.375</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35980</th>\n",
       "      <td>6425170194131031062</td>\n",
       "      <td>black</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>coveralls</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38850</th>\n",
       "      <td>2401791534489837026</td>\n",
       "      <td>pink</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>gloves and mittens</td>\n",
       "      <td>0.625</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40033</th>\n",
       "      <td>1904724343631049611</td>\n",
       "      <td>grey</td>\n",
       "      <td>girls</td>\n",
       "      <td>adidas</td>\n",
       "      <td>tops</td>\n",
       "      <td>6.000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46028</th>\n",
       "      <td>8412152782576815204</td>\n",
       "      <td>brown</td>\n",
       "      <td>unisex</td>\n",
       "      <td>kuling</td>\n",
       "      <td>boots</td>\n",
       "      <td>0.875</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item_no  colour gender_description         brand  \\\n",
       "3824   -1690395835756691110  purple              girls   mini rodini   \n",
       "4725    4011112455912821856   beige             unisex        kuling   \n",
       "9659     -92825680858531790   beige             unisex        kuling   \n",
       "12558   6592676930236846124    grey             unisex  buddy & hope   \n",
       "17515   6032649609097040334    blue             unisex          stoy   \n",
       "30965  -7258898587632840201    blue               boys        jacadi   \n",
       "35980   6425170194131031062   black             unisex        kuling   \n",
       "38850   2401791534489837026    pink             unisex        kuling   \n",
       "40033   1904724343631049611    grey              girls        adidas   \n",
       "46028   8412152782576815204   brown             unisex        kuling   \n",
       "\n",
       "               product_group  min_age  max_age  \n",
       "3824                 dresses    0.875     11.0  \n",
       "4725               coveralls    1.000     12.0  \n",
       "9659   fleeces and midlayers    0.125      2.0  \n",
       "12558          baby changing      NaN      NaN  \n",
       "17515               vehicles    6.000     10.0  \n",
       "30965              coveralls    0.375      2.0  \n",
       "35980              coveralls    1.000     12.0  \n",
       "38850     gloves and mittens    0.625      8.0  \n",
       "40033                   tops    6.000     14.0  \n",
       "46028                  boots    0.875     11.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = [item.numpy().decode() for item in titles[0]]\n",
    "item_info_df.loc[item_info_df['item_no'].isin(recommendations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f68b0",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3aee86",
   "metadata": {},
   "source": [
    "## **Baselines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb1e58",
   "metadata": {},
   "source": [
    "### **Top Items**\n",
    "\n",
    "**Let's find the top 100 items in the training dataset and always predict during the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOP_ITEMS = 100\n",
    "top_items = train_df_filtered['item_no'].value_counts()[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items_in_test_dataset = test_df_filtered.loc[test_df_filtered['item_no'].isin(top_items)]\n",
    "\n",
    "print(len(top_items_in_test_dataset))\n",
    "print(len(test_df_filtered['item_no'].unique()))\n",
    "print(len(test_df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db181635",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (1, 5, 10, 50, 100)\n",
    "metrics = [tf.keras.metrics.Mean() for k in ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_candidates = tf.expand_dims(tf.constant(test_df_filtered['item_no'].values), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e158b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_candidates = tf.expand_dims(top_items, 1)\n",
    "retrieved_candidates = tf.transpose(tf.repeat(retrieved_candidates, tf.constant(true_candidates.shape[0]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match = tf.cast(tf.math.equal(true_candidates, retrieved_candidates), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6454603",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, metric in zip(ks, metrics):\n",
    "    # By slicing until :k we assume scores are sorted.\n",
    "    # Clip to only count multiple matches once.\n",
    "    match_found = tf.clip_by_value(\n",
    "        tf.reduce_sum(ids_match[:, :k], axis=1, keepdims=True),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "    metric.update_state(match_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    print(metric.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945a0ae",
   "metadata": {},
   "source": [
    "### **Top Items Domain Knowledge**\n",
    "\n",
    "Since the test data is in November let's exclude certain product groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_df.loc[item_info_df['item_no'].isin(top_items)]['product_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c365cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS_TO_INCLUDE = ['jumpers and knitwear', 'coveralls', 'boots', 'coats and jackets', 'stroller accessories', \n",
    "                      'fleeces and midlayers', 'winter sets', 'gloves and mittens', 'headwear']\n",
    "\n",
    "items_to_consider = item_info_df.loc[item_info_df['product_group'].isin(GROUPS_TO_INCLUDE)]['item_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e42ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_items_filtered = train_df_filtered[\n",
    "    train_df_filtered['item_no'].isin(items_to_consider)]['item_no'].value_counts()[:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ee02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(top_items_filtered) - set(top_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd32c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_candidates = tf.expand_dims(top_items_filtered, 1)\n",
    "retrieved_candidates = tf.transpose(tf.repeat(retrieved_candidates, tf.constant(true_candidates.shape[0]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cffad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match = tf.cast(tf.math.equal(true_candidates, retrieved_candidates), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac17c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.Mean() for k in ks]\n",
    "for k, metric in zip(ks, metrics):\n",
    "    # By slicing until :k we assume scores are sorted.\n",
    "    # Clip to only count multiple matches once.\n",
    "    match_found = tf.clip_by_value(\n",
    "        tf.reduce_sum(ids_match[:, :k], axis=1, keepdims=True),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "    metric.update_state(match_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b18942",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    print(metric.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e734a",
   "metadata": {},
   "source": [
    "## Content-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_brands = train_df_filtered['brand'].value_counts()[:100].index\n",
    "top_groups = train_df_filtered['product_group'].value_counts()[:50].index\n",
    "train_df_filtered.loc[:, 'brand'] = train_df_filtered['brand'].apply(lambda x: x if x in top_brands else 'niche_brand')\n",
    "train_df_filtered.loc[:, 'product_group'] = train_df_filtered['product_group'].apply(lambda x: x if x in top_groups else 'niche_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b10ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_one_hot = pd.get_dummies(train_df_filtered[['user_no', 'gender_description', 'brand', 'product_group']], \n",
    "                                  columns=['gender_description', 'brand', 'product_group'])\n",
    "train_df_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = train_df_one_hot.groupby('user_no').agg('mean')\n",
    "\n",
    "user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec79b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_matrix = np.concatenate((np.zeros((1, 155)), user_embeddings.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding_layer = tf.keras.layers.Embedding(*user_embeddings_matrix.shape, \n",
    "                                                 embeddings_initializer=tf.keras.initializers.Constant(user_embeddings_matrix),\n",
    "                                                 trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=user_embeddings.index, \n",
    "      num_oov_indices=NUM_OOV_INDICES),\n",
    "  user_embedding_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_df.loc[:, 'brand'] = item_info_df['brand'].apply(lambda x: x if x in top_brands else 'niche_brand')\n",
    "item_info_df.loc[:, 'product_group'] = item_info_df['product_group'].apply(lambda x: x if x in top_groups else 'niche_group')\n",
    "item_embeddings = pd.get_dummies(item_info_df[['gender_description', 'brand', 'product_group']], \n",
    "                                 columns=['gender_description', 'brand', 'product_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings_matrix = np.concatenate((np.zeros((1, 155)), item_embeddings.values))\n",
    "\n",
    "item_embedding_layer = tf.keras.layers.Embedding(*item_embeddings_matrix.shape, \n",
    "                                                 embeddings_initializer=tf.keras.initializers.Constant(item_embeddings_matrix),\n",
    "                                                 trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=item_info_df['item_no'], \n",
    "      num_oov_indices=NUM_OOV_INDICES),\n",
    "  item_embedding_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model('206890150141030846')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dataset = tf.data.Dataset.from_tensor_slices(item_info_df['item_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(user_model)\n",
    "# recommends items out of the entire items dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((items_dataset.batch(100), items_dataset.batch(100).map(item_model)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = np.random.choice(train_df_filtered['user_no'].unique())\n",
    "train_df_filtered.loc[train_df_filtered['user_no'] == random_user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "items_to_exclude = train_df_filtered.loc[train_df_filtered['user_no'] == random_user]['item_no'].unique()\n",
    "_, titles = index.query_with_exclusions(tf.constant([random_user]), \n",
    "                                       tf.constant([items_to_exclude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28166995",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = [item.numpy().decode() for item in titles[0]]\n",
    "item_info_df.loc[item_info_df['item_no'].isin(recommendations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7717a",
   "metadata": {},
   "source": [
    "**Looks like it 'memorizes' users' tastes more**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111af655",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_dataset = tf.data.Dataset.from_tensor_slices(test_df_filtered['user_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e00863",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, retrieved_items = index(test_df_filtered['user_no'], k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_match = tf.cast(tf.math.equal(true_candidates, retrieved_items), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0164d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.Mean() for k in ks]\n",
    "for k, metric in zip(ks, metrics):\n",
    "    # By slicing until :k we assume scores are sorted.\n",
    "    # Clip to only count multiple matches once.\n",
    "    match_found = tf.clip_by_value(\n",
    "        tf.reduce_sum(ids_match[:, :k], axis=1, keepdims=True),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "    metric.update_state(match_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    print(metric.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b6600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Context Features\n",
    "\n",
    "Now let's add context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self, unique_users, num_oov_indices=1, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_users, \n",
    "                                         num_oov_indices=num_oov_indices),\n",
    "            tf.keras.layers.Embedding(len(unique_users) + num_oov_indices, embedding_dim)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.user_embedding(inputs['user_no'])\n",
    "    \n",
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 items, \n",
    "                 gender_description,\n",
    "                 top_brands, \n",
    "                 top_groups, \n",
    "                 num_oov_indices=1, \n",
    "                 embedding_dim=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=items, \n",
    "                                         num_oov_indices=num_oov_indices),\n",
    "            tf.keras.layers.Embedding(len(items) + num_oov_indices, 16)\n",
    "        ])\n",
    "        \n",
    "        self.gender_description_lookup = tf.keras.layers.StringLookup(vocabulary=gender_description, \n",
    "                                                                      output_mode='one_hot',\n",
    "                                                                      num_oov_indices=0)\n",
    "        self.brand_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=top_brands, \n",
    "                                         num_oov_indices=num_oov_indices),\n",
    "            tf.keras.layers.Embedding(len(top_brands) + num_oov_indices, 8)\n",
    "        ])\n",
    "        self.product_group_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=top_groups, \n",
    "                                         num_oov_indices=num_oov_indices),\n",
    "            tf.keras.layers.Embedding(len(top_groups) + num_oov_indices, 5)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "             self.item_embedding(inputs['item_no']),\n",
    "             self.gender_description_lookup(inputs['gender_description']),\n",
    "             self.brand_embedding(inputs['brand']),\n",
    "             self.product_group_embedding(inputs['product_group'])\n",
    "        ], axis=1)\n",
    "    \n",
    "class TFRSContextModel(tfrs.models.Model):\n",
    "    def __init__(self, \n",
    "                 unique_users,\n",
    "                 items, \n",
    "                 gender_description,\n",
    "                 top_brands, \n",
    "                 top_groups):\n",
    "        super().__init__()\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "            UserModel(unique_users), \n",
    "            #tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "            ItemModel(items, gender_description, top_brands, top_groups),\n",
    "            #tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items_dataset_w_context.batch(128).map(self.candidate_model)\n",
    "            )\n",
    "        )\n",
    "    def compute_loss(self, inputs, training=False):\n",
    "        query_embeddings = self.query_model({\n",
    "            'user_no': inputs['user_no']\n",
    "        })\n",
    "        candidate_embeddings = self.candidate_model({\n",
    "            'item_no': inputs['item_no'],\n",
    "            'gender_description': inputs['gender_description'],\n",
    "            'brand': inputs['brand'],\n",
    "            'product_group': inputs['product_group']\n",
    "        })\n",
    "        \n",
    "        return self.task(query_embeddings, candidate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697d5e6",
   "metadata": {},
   "source": [
    "**FIX ITEMS DATASET!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368891e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = item_info_df.loc[item_info_df['item_no'].isin(items)][\n",
    "    ['item_no', 'gender_description', 'brand', 'product_group']]\n",
    "\n",
    "items_dataset_w_context = tf.data.Dataset.from_tensor_slices(dict(items_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFRSContextModel(unique_users, items, gender_description, top_brands, top_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e65abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_dataset.shuffle(1_000).batch(1024).cache()\n",
    "cached_test = test_dataset.batch(512).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c45f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(cached_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11174bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "# recommends items out of the entire items dataset.\n",
    "_ = index.index_from_dataset(\n",
    "        tf.data.Dataset.zip((items_dataset.batch(100), \n",
    "                             items_dataset_w_context.batch(100).map(model.candidate_model))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf2003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597c67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17f5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d653bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataset.take(3).batch(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3daaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_brands = train_df_filtered['brand'].value_counts()[:100].index\n",
    "top_groups = train_df_filtered['product_group'].value_counts()[:50].index\n",
    "gender_description = train_df_filtered['gender_description'].unique()\n",
    "item_model = ItemModel(items, gender_description, top_brands, top_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b606ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataset.take(3).batch(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc28a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gender_description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde94d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.StringLookup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_lookup = tf.keras.layers.StringLookup(vocabulary=train_df['gender_description'].unique(), \n",
    "                                             output_mode='one_hot', \n",
    "                                             num_oov_indices=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c83adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_lookup(tf.constant(['boys']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2563fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c469c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba99f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff10056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd0b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dataset.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68055459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfrs-retail-example",
   "language": "python",
   "name": "tfrs-retail-example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
