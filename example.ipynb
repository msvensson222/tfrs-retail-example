{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_df = pd.read_csv(\"item_info.csv\").drop(columns=[\"min_age\", \"max_age\"])\n",
    "item_info_df[\"item_no\"] = item_info_df[\"item_no\"].astype(str)\n",
    "user_info_df = pd.read_csv(\"user_info.csv\")\n",
    "user_info_df[\"user_no\"] = user_info_df[\"user_no\"].astype(str)\n",
    "user_item_interaction_df = pd.read_csv(\"user_item_interactions.csv\")\n",
    "user_item_interaction_df[\"user_no\"] = user_item_interaction_df[\"user_no\"].astype(str)\n",
    "user_item_interaction_df[\"item_no\"] = user_item_interaction_df[\"item_no\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_no</th>\n",
       "      <th>colour</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206890150141030846</td>\n",
       "      <td>beige</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bloomingville</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7637494654837559066</td>\n",
       "      <td>pink</td>\n",
       "      <td>girls</td>\n",
       "      <td>petit bateau</td>\n",
       "      <td>clothing sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7969520735315050609</td>\n",
       "      <td>beige</td>\n",
       "      <td>unisex</td>\n",
       "      <td>bobo choses</td>\n",
       "      <td>jumpers and knitwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-565751122846696741</td>\n",
       "      <td>white</td>\n",
       "      <td>unisex</td>\n",
       "      <td>piupiuchick</td>\n",
       "      <td>tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6688930722259797984</td>\n",
       "      <td>green</td>\n",
       "      <td>unisex</td>\n",
       "      <td>filibabba</td>\n",
       "      <td>baby feeding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_no colour gender_description          brand  \\\n",
       "0   206890150141030846  beige             unisex  bloomingville   \n",
       "1  7637494654837559066   pink              girls   petit bateau   \n",
       "2  7969520735315050609  beige             unisex    bobo choses   \n",
       "3  -565751122846696741  white             unisex    piupiuchick   \n",
       "4  6688930722259797984  green             unisex      filibabba   \n",
       "\n",
       "          product_group  \n",
       "0             furniture  \n",
       "1         clothing sets  \n",
       "2  jumpers and knitwear  \n",
       "3                  tops  \n",
       "4          baby feeding  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_no</th>\n",
       "      <th>country</th>\n",
       "      <th>aov</th>\n",
       "      <th>avg_markdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8587933979694308845</td>\n",
       "      <td>sweden</td>\n",
       "      <td>479.2</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2740387653650048572</td>\n",
       "      <td>sweden</td>\n",
       "      <td>837.6</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2084988796719274722</td>\n",
       "      <td>sweden</td>\n",
       "      <td>942.4</td>\n",
       "      <td>-0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4662401680846085311</td>\n",
       "      <td>sweden</td>\n",
       "      <td>438.4</td>\n",
       "      <td>-0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1086148156436227367</td>\n",
       "      <td>sweden</td>\n",
       "      <td>664.8</td>\n",
       "      <td>-0.286667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_no country    aov  avg_markdown\n",
       "0   8587933979694308845  sweden  479.2     -0.200000\n",
       "1   2740387653650048572  sweden  837.6     -0.200000\n",
       "2   2084988796719274722  sweden  942.4     -0.560000\n",
       "3  -4662401680846085311  sweden  438.4     -0.620000\n",
       "4  -1086148156436227367  sweden  664.8     -0.286667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_no</th>\n",
       "      <th>item_no</th>\n",
       "      <th>date</th>\n",
       "      <th>eventtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>purchased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>2658388892627023500</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>pageView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>504233002877562247</td>\n",
       "      <td>2021-11-26</td>\n",
       "      <td>pageView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>-3413566329152665076</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>pageView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>6700254580945881296</td>\n",
       "      <td>2021-10-10</td>\n",
       "      <td>pageView</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_no               item_no        date  eventtype\n",
       "0  9060639138425951676   -478270421339298398  2021-06-24  purchased\n",
       "1  9060639138425951676   2658388892627023500  2021-11-27   pageView\n",
       "2  9060639138425951676    504233002877562247  2021-11-26   pageView\n",
       "3  9060639138425951676  -3413566329152665076  2021-10-21   pageView\n",
       "4  9060639138425951676   6700254580945881296  2021-10-10   pageView"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_interaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pageView         411685\n",
       "addToCart        354022\n",
       "purchased        227165\n",
       "addToWishlist     18353\n",
       "Name: eventtype, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_interaction_df[\"eventtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook structure\n",
    "Overall thought: Make a simple example using one or two features, but providing a working example to inspire the audience to go test by themselves, since there are more features in the data. Same logic with the model complexity.\n",
    "\n",
    "Use a lot of the stuff from the TFRS tutorials when it comes to batch-sizes and loss functions to make it \"relatable\".\n",
    "\n",
    "## Load data\n",
    "* Whats done above this cell already\n",
    "## Prepare data\n",
    "* Choose features\n",
    "* Preprocess (missing values / standardize  etc)\n",
    "* Split data train/test\n",
    "* Create TF Dataset\n",
    "## Model creation\n",
    "* Create one Query Model and one Candidate model (use same terminology as in the presentation). Maybe skip the dense layers?\n",
    "* Create one TFRS model, with appropriate task and loss function using the two tower model architecture.\n",
    "## Model training\n",
    "* Would be nice if we had it set up so you could train both on GPU or CPU. So baiscally a flag if you want to use GPU or not (or check if GPU attached automatically). \n",
    "* Train for n epochs\n",
    "* Important to set training=False in the loss function, otherwise it evaluates during every epoch on the train data, which is painfully slow. So something like (def compute_loss(self, features, training=False) -> tf.Tensor:)\n",
    "\n",
    "## Model evaluation\n",
    "* Evaluate on test and train, show difference between Top-100 accuracy\n",
    "* Show that it overfits easily, just like any NN, so need to apply regularization and early stopping if you want it to generalize well (maybe not implement this)\n",
    "\n",
    "## Model serving\n",
    "* Create an index, and predict on one customer, show speed of inference. Batch-predict over all users and show ms/user of inference speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FEATURES = [\n",
    "    \"user_no\",\n",
    "    \"aov\"\n",
    "]\n",
    "ITEM_FEATURES = [\n",
    "    \"item_no\",\n",
    "    \"brand\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df_to_ds(df: pd.DataFrame, training: bool = False):\n",
    "    tf.random.set_seed(42)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(df.to_dict('list'))\n",
    "    ds = ds.map(lambda x: {feat: x[feat] for feat in df.columns.to_list()})\n",
    "    if training:\n",
    "        return ds.shuffle(1_000_000, seed=42, reshuffle_each_iteration=False)\n",
    "    else:\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ds = transform_df_to_ds(item_info_df[ITEM_FEATURES]).batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_df[\"aov\"] = (user_info_df[\"aov\"]-user_info_df[\"aov\"].mean())/user_info_df[\"aov\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_with_features_df = user_item_interaction_df[[\"item_no\", \"user_no\"]].merge(\n",
    "    item_info_df[ITEM_FEATURES], on=\"item_no\", how=\"inner\").merge(\n",
    "    user_info_df[USER_FEATURES], on=\"user_no\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_with_features_df[\"aov\"].fillna(interaction_with_features_df[\"aov\"].median(), inplace=True)\n",
    "interaction_with_features_df[\"brand\"].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_no</th>\n",
       "      <th>user_no</th>\n",
       "      <th>brand</th>\n",
       "      <th>aov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>aden + anais</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>aden + anais</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>9060639138425951676</td>\n",
       "      <td>aden + anais</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>4759906564227534049</td>\n",
       "      <td>aden + anais</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-478270421339298398</td>\n",
       "      <td>-6088219459028908639</td>\n",
       "      <td>aden + anais</td>\n",
       "      <td>0.174368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011220</th>\n",
       "      <td>3602204210967538706</td>\n",
       "      <td>523748455264982590</td>\n",
       "      <td>djeco</td>\n",
       "      <td>0.135320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011221</th>\n",
       "      <td>-8379298112698763661</td>\n",
       "      <td>1176391229201836984</td>\n",
       "      <td>jacadi</td>\n",
       "      <td>-0.300428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011222</th>\n",
       "      <td>3361370720256307796</td>\n",
       "      <td>-3683116124016444198</td>\n",
       "      <td>jacadi</td>\n",
       "      <td>-0.572064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011223</th>\n",
       "      <td>-422153658955051132</td>\n",
       "      <td>4666521970382148688</td>\n",
       "      <td>billieblush</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011224</th>\n",
       "      <td>981298674982707936</td>\n",
       "      <td>7068348551466544329</td>\n",
       "      <td>nadadelazos</td>\n",
       "      <td>-0.148118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      item_no               user_no         brand       aov\n",
       "0         -478270421339298398   9060639138425951676  aden + anais -0.148118\n",
       "1         -478270421339298398   9060639138425951676  aden + anais -0.148118\n",
       "2         -478270421339298398   9060639138425951676  aden + anais -0.148118\n",
       "3         -478270421339298398   4759906564227534049  aden + anais -0.148118\n",
       "4         -478270421339298398  -6088219459028908639  aden + anais  0.174368\n",
       "...                       ...                   ...           ...       ...\n",
       "1011220   3602204210967538706    523748455264982590         djeco  0.135320\n",
       "1011221  -8379298112698763661   1176391229201836984        jacadi -0.300428\n",
       "1011222   3361370720256307796  -3683116124016444198        jacadi -0.572064\n",
       "1011223   -422153658955051132   4666521970382148688   billieblush -0.148118\n",
       "1011224    981298674982707936   7068348551466544329   nadadelazos -0.148118\n",
       "\n",
       "[1011225 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_with_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_with_features_df_train, interaction_with_features_df_test = train_test_split(interaction_with_features_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes in train and val respectively:  808980, 202245\n"
     ]
    }
   ],
   "source": [
    "train = transform_df_to_ds(interaction_with_features_df_train, training=True)\n",
    "test = transform_df_to_ds(interaction_with_features_df_test)\n",
    "print(f\"Sample sizes in train and val respectively:  {len(train)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(dataset, feature):\n",
    "    vocab = dataset[feature].value_counts().index.to_list()  # Makes sure they are sorted if you only want to keep the most popular ones\n",
    "    unique_ids = np.delete(vocab, np.argwhere(vocab == \"unknown\"))\n",
    "    return unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user model\n",
    "def create_user_model():\n",
    "    user_vocab = get_vocabulary(user_info_df, \"user_no\")\n",
    "\n",
    "    user_input = tf.keras.Input(shape=(1,), dtype=\"string\", name=\"user_no\")\n",
    "    user_look_up = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                    vocabulary=user_vocab,\n",
    "                    mask_token=None,\n",
    "                    name=f\"SL_user_no\")(user_input)\n",
    "    user_embedding_layer = tf.keras.layers.Embedding(len(user_vocab) + 1,\n",
    "                                                71,\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.l2(0),\n",
    "                                                name=f\"Embedding_user_no\")(user_look_up)\n",
    "    user_flattened_embeddings = tf.keras.layers.Flatten(name=f\"Flatten_user_no\")(user_embedding_layer)\n",
    "\n",
    "    aov_input = tf.keras.Input(shape=(1,), dtype=\"float64\", name=\"aov\")\n",
    "    output = tf.keras.layers.concatenate([user_flattened_embeddings, aov_input])\n",
    "    # Could include dropout here as well\n",
    "    \n",
    "    #output = tf.keras.layers.Dense(32,\n",
    "    #                           kernel_regularizer=tf.keras.regularizers.l2(0),\n",
    "    #                           activation=None,\n",
    "    #                           name=\"user_embedding\")(output)\n",
    "\n",
    "    return tf.keras.models.Model([user_input, aov_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_no (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "SL_user_no (StringLookup)       (None, 1)            0           user_no[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_user_no (Embedding)   (None, 1, 71)        1742624     SL_user_no[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_user_no (Flatten)       (None, 71)           0           Embedding_user_no[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "aov (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72)           0           Flatten_user_no[0][0]            \n",
      "                                                                 aov[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,742,624\n",
      "Trainable params: 1,742,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "user_model = create_user_model()\n",
    "user_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the item model\n",
    "def create_item_model():\n",
    "    item_vocab = get_vocabulary(interaction_with_features_df, \"item_no\")\n",
    "\n",
    "    item_input = tf.keras.Input(shape=(1,), dtype=\"string\", name=\"item_no\")\n",
    "    item_look_up = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                    vocabulary=item_vocab,\n",
    "                    mask_token=None,\n",
    "                    name=f\"SL_item_no\")(item_input)\n",
    "    item_embedding_layer = tf.keras.layers.Embedding(len(item_vocab) + 1,\n",
    "                                                64,\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.l2(0),\n",
    "                                                name=f\"Embedding_item_no\")(item_look_up)\n",
    "    item_flattened_embeddings = tf.keras.layers.Flatten(name=f\"Flatten_item_no\")(item_embedding_layer)\n",
    "    \n",
    "    # Add brand feature\n",
    "    brand_vocab = get_vocabulary(interaction_with_features_df, \"brand\")\n",
    "\n",
    "    brand_input = tf.keras.Input(shape=(1,), dtype=\"string\", name=\"brand\")\n",
    "    brand_look_up = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                    vocabulary=brand_vocab,\n",
    "                    mask_token=None,\n",
    "                    name=f\"SL_brand\")(brand_input)\n",
    "    brand_embedding_layer = tf.keras.layers.Embedding(len(brand_vocab) + 1,\n",
    "                                                8,\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.l2(0),\n",
    "                                                name=f\"Embedding_brand\")(brand_look_up)\n",
    "    brand_flattened_embeddings = tf.keras.layers.Flatten(name=f\"Flatten_brand\")(brand_embedding_layer)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([item_flattened_embeddings, brand_flattened_embeddings])\n",
    "    # Could include dropout here as well\n",
    "    \n",
    "    #output = tf.keras.layers.Dense(32,\n",
    "    #                       kernel_regularizer=tf.keras.regularizers.l2(0),\n",
    "    #                       activation=None,\n",
    "    #                       name=\"item_embedding\")(output)\n",
    "\n",
    "    return tf.keras.models.Model([item_input, brand_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_no (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "brand (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "SL_item_no (StringLookup)       (None, 1)            0           item_no[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "SL_brand (StringLookup)         (None, 1)            0           brand[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_item_no (Embedding)   (None, 1, 64)        3949056     SL_item_no[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_brand (Embedding)     (None, 1, 8)         5160        SL_brand[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_item_no (Flatten)       (None, 64)           0           Embedding_item_no[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_brand (Flatten)         (None, 8)            0           Embedding_brand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 72)           0           Flatten_item_no[0][0]            \n",
      "                                                                 Flatten_brand[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,954,216\n",
      "Trainable params: 3,954,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "item_model = create_item_model()\n",
    "item_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetrievalModel(tfrs.models.Model):\n",
    "    def __init__(self, item_model, user_model, items_ds):\n",
    "        super().__init__()\n",
    "        self.item_model = item_model\n",
    "        self.user_model = user_model\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(candidates=items_ds.map(self.item_model)))\n",
    "\n",
    "    \n",
    "    def call(self, features):\n",
    "        user_embeddings = self.user_model(features)\n",
    "        item_embeddings = self.item_model(features)\n",
    "        return user_embeddings, item_embeddings\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings, item_embeddings = self(features)\n",
    "        loss = self.task(user_embeddings,\n",
    "                         item_embeddings,\n",
    "                         compute_metrics=not training)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "PATIENCE = 3\n",
    "BATCH_SIZE = 4096\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomRetrievalModel(item_model,\n",
    "                             user_model,\n",
    "                             items_ds)\n",
    "\n",
    "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_factorized_top_k/top_100_categorical_accuracy',\n",
    "    patience=PATIENCE, restore_best_weights=True, mode=\"max\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['item_no', 'brand'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['user_no', 'aov'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 104s 516ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 33379.2417 - regularization_loss: 0.0000e+00 - total_loss: 33379.2417 - val_factorized_top_k/top_1_categorical_accuracy: 0.0099 - val_factorized_top_k/top_5_categorical_accuracy: 0.0372 - val_factorized_top_k/top_10_categorical_accuracy: 0.0476 - val_factorized_top_k/top_50_categorical_accuracy: 0.0725 - val_factorized_top_k/top_100_categorical_accuracy: 0.0853 - val_loss: 10550.5078 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10550.5078\n",
      "Epoch 2/5\n",
      "198/198 [==============================] - 100s 498ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 29986.6858 - regularization_loss: 0.0000e+00 - total_loss: 29986.6858 - val_factorized_top_k/top_1_categorical_accuracy: 0.0096 - val_factorized_top_k/top_5_categorical_accuracy: 0.0433 - val_factorized_top_k/top_10_categorical_accuracy: 0.0570 - val_factorized_top_k/top_50_categorical_accuracy: 0.0844 - val_factorized_top_k/top_100_categorical_accuracy: 0.0981 - val_loss: 10634.6523 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10634.6523\n",
      "Epoch 3/5\n",
      "198/198 [==============================] - 100s 499ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 28650.9938 - regularization_loss: 0.0000e+00 - total_loss: 28650.9938 - val_factorized_top_k/top_1_categorical_accuracy: 0.0102 - val_factorized_top_k/top_5_categorical_accuracy: 0.0497 - val_factorized_top_k/top_10_categorical_accuracy: 0.0679 - val_factorized_top_k/top_50_categorical_accuracy: 0.0987 - val_factorized_top_k/top_100_categorical_accuracy: 0.1116 - val_loss: 10705.0186 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10705.0186\n",
      "Epoch 4/5\n",
      "198/198 [==============================] - 101s 501ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 28020.3225 - regularization_loss: 0.0000e+00 - total_loss: 28020.3225 - val_factorized_top_k/top_1_categorical_accuracy: 0.0106 - val_factorized_top_k/top_5_categorical_accuracy: 0.0520 - val_factorized_top_k/top_10_categorical_accuracy: 0.0733 - val_factorized_top_k/top_50_categorical_accuracy: 0.1061 - val_factorized_top_k/top_100_categorical_accuracy: 0.1182 - val_loss: 10792.3252 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10792.3252\n",
      "Epoch 5/5\n",
      "198/198 [==============================] - 100s 499ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 27680.4641 - regularization_loss: 0.0000e+00 - total_loss: 27680.4641 - val_factorized_top_k/top_1_categorical_accuracy: 0.0108 - val_factorized_top_k/top_5_categorical_accuracy: 0.0536 - val_factorized_top_k/top_10_categorical_accuracy: 0.0771 - val_factorized_top_k/top_50_categorical_accuracy: 0.1102 - val_factorized_top_k/top_100_categorical_accuracy: 0.1209 - val_loss: 10842.6680 - val_regularization_loss: 0.0000e+00 - val_total_loss: 10842.6680\n"
     ]
    }
   ],
   "source": [
    "if USE_GPU:\n",
    "    gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(f\"Using {len(gpus)} GPU's. Devices: {gpus}\")\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=gpus)\n",
    "\n",
    "    with strategy.scope():\n",
    "        model.fit(train.batch(BATCH_SIZE),\n",
    "                  epochs=N_EPOCHS,\n",
    "                  validation_data=test.batch(BATCH_SIZE),\n",
    "                  callbacks=[callback_early_stopping])\n",
    "        \n",
    "else:\n",
    "    model.fit(train.batch(BATCH_SIZE),\n",
    "          epochs=N_EPOCHS,\n",
    "          validation_data=test.batch(BATCH_SIZE),\n",
    "          callbacks=[callback_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 78s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0215 - factorized_top_k/top_5_categorical_accuracy: 0.1075 - factorized_top_k/top_10_categorical_accuracy: 0.1602 - factorized_top_k/top_50_categorical_accuracy: 0.2388 - factorized_top_k/top_100_categorical_accuracy: 0.2575 - loss: 26955.0921 - regularization_loss: 0.0000e+00 - total_loss: 26955.0921\n",
      "50/50 [==============================] - 75s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0108 - factorized_top_k/top_5_categorical_accuracy: 0.0536 - factorized_top_k/top_10_categorical_accuracy: 0.0771 - factorized_top_k/top_50_categorical_accuracy: 0.1102 - factorized_top_k/top_100_categorical_accuracy: 0.1209 - loss: 32207.2955 - regularization_loss: 0.0000e+00 - total_loss: 32207.2955\n",
      "Train top-100 accuracy:  0.2574847340583801\n",
      "Test top-100 accuracy:  0.12093747407197952\n"
     ]
    }
   ],
   "source": [
    "train_top_100_accuracy = model.evaluate(train.take(len(test)).batch(BATCH_SIZE), return_dict=True)\n",
    "val_top_100_accuracy = model.evaluate(test.batch(BATCH_SIZE), return_dict=True)\n",
    "print(f\"Train top-100 accuracy:  {train_top_100_accuracy['factorized_top_k/top_100_categorical_accuracy']}\")\n",
    "print(f\"Test top-100 accuracy:  {val_top_100_accuracy['factorized_top_k/top_100_categorical_accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f277fe22210>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serving\n",
    "k=100\n",
    "brute_force_index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=k)\n",
    "brute_force_index.index_from_dataset(\n",
    "    items_ds.map(lambda item: (item[\"item_no\"], model.item_model(item)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['country', 'avg_markdown'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       "array([b'-1862413450221128561', b'2415771766691761607',\n",
       "       b'-5229418859057656862', b'4841275771541059511',\n",
       "       b'-8630133537136090944'], dtype=object)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {k: np.array(v) for k, v in user_info_df.head(1).to_dict('list').items()}\n",
    "_, recommendations = brute_force_index(user_input)\n",
    "recommendations[0][:5] # Top 5 items for one user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for top-100 item recommendations for 20000 number of users completed in 2.57 seconds.\n",
      "Average inference time per user is 0.13ms \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 500\n",
    "N_USERS_TO_PREDICT_FOR = 20_000\n",
    "\n",
    "start_timer = time.time()\n",
    "for i in range(0, N_USERS_TO_PREDICT_FOR, BATCH_SIZE):\n",
    "    user_input = {k: np.array(v) for k, v in user_info_df.iloc[i:i + BATCH_SIZE].to_dict('list').items()}\n",
    "    _, recommendations = brute_force_index(user_input)\n",
    "\n",
    "print(\n",
    "    f\"Inference for top-{k} item recommendations for {N_USERS_TO_PREDICT_FOR} number of users completed in {time.time()-start_timer:.2f} seconds.\"\n",
    "    f\"\\nAverage inference time per user is {(time.time()-start_timer)/N_USERS_TO_PREDICT_FOR*1000:.2f}ms \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
